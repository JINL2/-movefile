#!/usr/bin/env python3
"""
Step 1: Supabase Polling Service (EXE ë¹Œë“œìš©)
Supabaseì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ Step 2 APIë¡œ ì „ì†¡í•˜ëŠ” í´ë§ ì„œë¹„ìŠ¤

ë¹Œë“œ ë°©ë²•:
pip install pyinstaller requests
pyinstaller --onefile --name "Step1_Supabase_Polling" step1_polling_service.py
"""

import json
import time
import requests
import logging
from datetime import datetime
import sys
import os
from typing import Dict, List, Optional

# ==================== ì„¤ì • ë³€ìˆ˜ (ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”) ====================

# Supabase ì„¤ì •
SUPABASE_URL = 'https://yenfccoefczqxckbizqa.supabase.co'
SUPABASE_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InllbmZjY29lZmN6cXhja2JpenFhIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDU5NDkyNzksImV4cCI6MjA2MTUyNTI3OX0.U1iQUOaNPSrEHf1w_ePqgYzJiRO6Bi48E2Np2hY0nCQ'

# í…Œì´ë¸” ë° ì»¬ëŸ¼ ì„¤ì •
TABLE_NAME = 'contents_idea'
COLUMN_IS_FETCHED = 'is_fetched'
COLUMN_IS_AUTO_CREATED = 'is_auto_created'
COLUMN_ID = 'id'
COLUMN_TITLE_KO = 'title_ko'
COLUMN_TITLE_VI = 'title_vi'
COLUMN_SCENARIO = 'scenario'
COLUMN_COMPANY_ID = 'company_id'
COLUMN_STORE_ID = 'store_id'

# API ì„¤ì •
STEP2_API_URL = 'http://localhost:5001'
API_TYPE = 'create_contents_on_user_idea'

# í´ë§ ì„¤ì •
POLLING_INTERVAL = 30  # ì´ˆ ë‹¨ìœ„
BATCH_SIZE = 1  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë°ì´í„° ê°œìˆ˜
RETRY_DELAY = 30  # API ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„

# ë¡œê·¸ ì„¤ì •
LOG_DIR = 'logs'  # ë¡œê·¸ ë””ë ‰í† ë¦¬
LOG_FILE = 'step1_polling.log'
LOG_LEVEL = logging.INFO
LOG_RETENTION_DAYS = 1  # ë¡œê·¸ ë³´ê´€ ì¼ìˆ˜

# ========================================================================

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
def create_log_directory():
    """ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±"""
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

# ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬
def cleanup_old_logs():
    """ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì‚­ì œ"""
    try:
        log_path = os.path.join(LOG_DIR, LOG_FILE)
        if os.path.exists(log_path):
            # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
            file_modified_time = datetime.fromtimestamp(os.path.getmtime(log_path))
            current_time = datetime.now()
            
            # í•˜ë£¨ ì´ìƒ ì§€ë‚œ ë¡œê·¸ íŒŒì¼ ì‚­ì œ
            if (current_time - file_modified_time).days >= LOG_RETENTION_DAYS:
                os.remove(log_path)
                print(f"Old log file deleted: {log_path}")
    except Exception as e:
        print(f"Error cleaning up logs: {e}")

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    create_log_directory()
    cleanup_old_logs()
    
    log_path = os.path.join(LOG_DIR, LOG_FILE)
    
    # ë¡œê·¸ í¬ë§·í„°
    formatter = logging.Formatter(
        '%(asctime)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    file_handler = logging.FileHandler(log_path, encoding='utf-8')
    file_handler.setFormatter(formatter)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger(__name__)
    logger.setLevel(LOG_LEVEL)
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

class SupabasePoller:
    """Supabase í´ë§ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.headers = {
            'apikey': SUPABASE_KEY,
            'Authorization': f'Bearer {SUPABASE_KEY}',
            'Content-Type': 'application/json'
        }
        self.processed_count = 0
        self.error_count = 0
        
    def fetch_unfetched_ideas(self) -> List[Dict]:
        """ë¯¸ì²˜ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = f"{SUPABASE_URL}/rest/v1/{TABLE_NAME}"
            params = {
                f'{COLUMN_IS_AUTO_CREATED}': 'eq.false',
                f'{COLUMN_IS_FETCHED}': 'eq.false',
                'select': '*',
                'order': 'created_at.asc',
                'limit': BATCH_SIZE
            }
            
            response = requests.get(url, headers=self.headers, params=params)
            response.raise_for_status()
            
            ideas = response.json()
            if ideas:
                logger.info(f"âœ… {len(ideas)}ê°œì˜ ìƒˆ ë°ì´í„° ë°œê²¬")
            return ideas
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def update_is_fetched(self, idea_id: int) -> bool:
        """is_fetched í”Œë˜ê·¸ ì—…ë°ì´íŠ¸"""
        try:
            url = f"{SUPABASE_URL}/rest/v1/{TABLE_NAME}?{COLUMN_ID}=eq.{idea_id}"
            data = {COLUMN_IS_FETCHED: True}
            
            headers = self.headers.copy()
            headers['Prefer'] = 'return=minimal'
            
            response = requests.patch(url, headers=headers, json=data)
            response.raise_for_status()
            
            logger.info(f"âœ… ID {idea_id}ì˜ {COLUMN_IS_FETCHED} ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ID {idea_id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def send_to_step2(self, idea: Dict) -> bool:
        """Step 2 APIë¡œ ë°ì´í„° ì „ì†¡"""
        try:
            # API íƒ€ì… ì¶”ê°€
            idea_with_type = idea.copy()
            idea_with_type['api_type'] = API_TYPE
            
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ìš”ì²­
            url = f"{STEP2_API_URL}/workflows/create_contents/run"
            response = requests.post(url, json=idea_with_type, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"âœ… Step 2 API ì „ì†¡ ì„±ê³µ: {result.get('message', 'Success')}")
                if result.get('job_id'):
                    logger.info(f"   ì‘ì—… ID: {result['job_id']}")
                return True
            else:
                logger.error(f"âŒ Step 2 API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return False
                
        except requests.exceptions.ConnectionError:
            logger.error("âŒ Step 2 API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return False
        except Exception as e:
            logger.error(f"âŒ Step 2 API ì „ì†¡ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def process_idea(self, idea: Dict) -> bool:
        """ë‹¨ì¼ ì•„ì´ë””ì–´ ì²˜ë¦¬"""
        try:
            idea_id = idea.get(COLUMN_ID)
            title = idea.get(COLUMN_TITLE_KO) or idea.get(COLUMN_TITLE_VI) or 'No Title'
            
            logger.info(f"ğŸ“¤ ì²˜ë¦¬ ì¤‘: ID={idea_id}, ì œëª©={title}")
            
            # Step 2ë¡œ ì „ì†¡
            if self.send_to_step2(idea):
                # ì„±ê³µ ì‹œ is_fetched ì—…ë°ì´íŠ¸
                if self.update_is_fetched(idea_id):
                    self.processed_count += 1
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"âŒ ì•„ì´ë””ì–´ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            self.error_count += 1
            return False
    
    def check_step2_status(self) -> bool:
        """Step 2 API ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(f"{STEP2_API_URL}/status", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def run(self):
        """ë©”ì¸ í´ë§ ë£¨í”„"""
        logger.info("=" * 60)
        logger.info("ğŸš€ Supabase í´ë§ ì„œë¹„ìŠ¤ ì‹œì‘")
        logger.info(f"ğŸ“ Supabase URL: {SUPABASE_URL}")
        logger.info(f"ğŸ“¡ Step 2 API: {STEP2_API_URL}")
        logger.info(f"â±ï¸  í´ë§ ê°„ê²©: {POLLING_INTERVAL}ì´ˆ")
        logger.info(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}ê°œ")
        logger.info(f"ğŸ“‚ ë¡œê·¸ ìœ„ì¹˜: {os.path.join(LOG_DIR, LOG_FILE)}")
        logger.info("=" * 60)
        
        # ë¡œê·¸ ì •ë¦¬ ì£¼ê¸° ì„¤ì • (í•˜ë£¨ì— í•œ ë²ˆ)
        last_cleanup = datetime.now()
        
        # ì´ˆê¸° Step 2 ìƒíƒœ í™•ì¸
        if not self.check_step2_status():
            logger.warning("âš ï¸  Step 2 API ì„œë²„ê°€ ì˜¤í”„ë¼ì¸ ìƒíƒœì…ë‹ˆë‹¤.")
            logger.warning("   ê³„ì† ì§„í–‰í•˜ì§€ë§Œ ë°ì´í„° ì „ì†¡ì€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        while True:
            try:
                # ë¯¸ì²˜ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                ideas = self.fetch_unfetched_ideas()
                
                if ideas:
                    # ê° ì•„ì´ë””ì–´ ì²˜ë¦¬
                    for idea in ideas:
                        self.process_idea(idea)
                        time.sleep(0.5)  # ê° ì²˜ë¦¬ ì‚¬ì´ ì§§ì€ ëŒ€ê¸°
                    
                    logger.info(f"ğŸ“Š í†µê³„: ì²˜ë¦¬ë¨={self.processed_count}, ì˜¤ë¥˜={self.error_count}")
                else:
                    logger.debug("ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # í•˜ë£¨ì— í•œ ë²ˆ ë¡œê·¸ ì •ë¦¬
                current_time = datetime.now()
                if (current_time - last_cleanup).days >= 1:
                    cleanup_old_logs()
                    last_cleanup = current_time
                    logger.info("ğŸ§¹ ë¡œê·¸ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                
                # ë‹¤ìŒ í´ë§ê¹Œì§€ ëŒ€ê¸°
                time.sleep(POLLING_INTERVAL)
                
            except KeyboardInterrupt:
                logger.info("\nâ¹ï¸  ì‚¬ìš©ìê°€ ì„œë¹„ìŠ¤ë¥¼ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤.")
                break
            except Exception as e:
                logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
                logger.info(f"â³ {RETRY_DELAY}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(RETRY_DELAY)
        
        logger.info(f"ğŸ ì„œë¹„ìŠ¤ ì¢…ë£Œ. ì´ ì²˜ë¦¬: {self.processed_count}ê°œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        poller = SupabasePoller()
        poller.run()
    except Exception as e:
        logger.error(f"âŒ ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
        input("Press Enter to exit...")
        sys.exit(1)

if __name__ == "__main__":
    main()
